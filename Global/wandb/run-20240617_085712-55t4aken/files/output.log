CustomDatasetDataLoader
dataset [UnPairOldPhotos_SR] was created
start load bigfile (0.64 GB) into memory
find total 853 images
load 0 images done
load all 853 images done
-------------Filter the imgs whose size <256 in VOC-------------
Image read error for index 34: 133.jpg
Image read error for index 74: 177.jpg
Image read error for index 158: 26.jpg
/home/quan/miniconda3/envs/photo/lib/python3.8/site-packages/PIL/Image.py:1000: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images
  warnings.warn(
Image read error for index 251: 355.jpg
Image read error for index 334: 452.jpg
Image read error for index 434: 563.jpg
Image read error for index 495: 627.jpg
Image read error for index 530: 666.jpg
Image read error for index 578: 711.jpg
Image read error for index 656: 791.jpg
Image read error for index 755: 893.jpg
--------Origin image num is [853], filtered result is [848]--------
#training images = 846
Resuming from epoch 20 at iteration 0
GlobalGenerator_DCDCv2(
  (encoder): Sequential(
    (0): ReflectionPad2d((3, 3, 3, 3))
    (1): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1))
    (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (3): ReLU(inplace=True)
    (4): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (5): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (6): ReLU(inplace=True)
    (7): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (8): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (9): ReLU(inplace=True)
    (10): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): ReLU(inplace=True)
        (4): ReflectionPad2d((1, 1, 1, 1))
        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
        (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (11): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): ReLU(inplace=True)
        (4): ReflectionPad2d((1, 1, 1, 1))
        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
        (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (12): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): ReLU(inplace=True)
        (4): ReflectionPad2d((1, 1, 1, 1))
        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
        (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (13): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): ReLU(inplace=True)
        (4): ReflectionPad2d((1, 1, 1, 1))
        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
        (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
  )
  (decoder): Sequential(
    (0): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): ReLU(inplace=True)
        (4): ReflectionPad2d((1, 1, 1, 1))
        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
        (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (1): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): ReLU(inplace=True)
        (4): ReflectionPad2d((1, 1, 1, 1))
        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
        (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (2): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): ReLU(inplace=True)
        (4): ReflectionPad2d((1, 1, 1, 1))
        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
        (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (3): ResnetBlock(
      (conv_block): Sequential(
        (0): ReflectionPad2d((1, 1, 1, 1))
        (1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
        (2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (3): ReLU(inplace=True)
        (4): ReflectionPad2d((1, 1, 1, 1))
        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))
        (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (4): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (5): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (6): ReLU(inplace=True)
    (7): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (8): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (9): ReLU(inplace=True)
    (10): ReflectionPad2d((3, 3, 3, 3))
    (11): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1))
    (12): Tanh()
  )
)
MultiscaleDiscriminator(
  (scale0_layer0): Sequential(
    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (scale0_layer1): Sequential(
    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))
    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (scale0_layer2): Sequential(
    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))
    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (scale0_layer3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))
    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (scale0_layer4): Sequential(
    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))
  )
  (scale1_layer0): Sequential(
    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))
    (1): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (scale1_layer1): Sequential(
    (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))
    (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (scale1_layer2): Sequential(
    (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))
    (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (scale1_layer3): Sequential(
    (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))
    (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
    (2): LeakyReLU(negative_slope=0.2, inplace=True)
  )
  (scale1_layer4): Sequential(
    (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))
  )
  (downsample): AvgPool2d(kernel_size=3, stride=2, padding=[1, 1])
)
---------- G Networks reloaded -------------
---------- D Networks reloaded -------------
/home/quan/miniconda3/envs/photo/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/quan/miniconda3/envs/photo/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
---------- Optimizers initialized -------------
---------- Optimizers reloaded -------------
---------- Current LR is 0.00000400 -------------
/home/quan/workspace/image-restoration/Global/models/networks.py:808: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:78.)
  fake_tensor = self.Tensor(input.size()).fill_(self.fake_label)
End of epoch 21 / 200 	 Time Taken: 46 sec
saving the model at the end of epoch 21, iters 17766
(epoch: 22, iters: 54, time: 0.043 lr: 0.00000) G_GAN: 0.892 G_GAN_Feat: 6.811 G_VGG: 8.881 G_KL: 0.803 D_real: 0.333 D_fake: 0.352
End of epoch 22 / 200 	 Time Taken: 37 sec
saving the model at the end of epoch 22, iters 18612
(epoch: 23, iters: 108, time: 0.042 lr: 0.00000) G_GAN: 0.988 G_GAN_Feat: 6.375 G_VGG: 9.045 G_KL: 0.777 D_real: 0.407 D_fake: 0.304
End of epoch 23 / 200 	 Time Taken: 36 sec
saving the model at the end of epoch 23, iters 19458
(epoch: 24, iters: 162, time: 0.042 lr: 0.00000) G_GAN: 0.952 G_GAN_Feat: 6.192 G_VGG: 9.384 G_KL: 0.759 D_real: 0.385 D_fake: 0.314
End of epoch 24 / 200 	 Time Taken: 36 sec
saving the model at the end of epoch 24, iters 20304
(epoch: 25, iters: 216, time: 0.042 lr: 0.00000) G_GAN: 0.927 G_GAN_Feat: 6.760 G_VGG: 9.029 G_KL: 0.859 D_real: 0.381 D_fake: 0.357
End of epoch 25 / 200 	 Time Taken: 36 sec
saving the model at the end of epoch 25, iters 21150
(epoch: 26, iters: 270, time: 0.042 lr: 0.00000) G_GAN: 1.041 G_GAN_Feat: 5.991 G_VGG: 8.226 G_KL: 0.783 D_real: 0.307 D_fake: 0.277
End of epoch 26 / 200 	 Time Taken: 36 sec
saving the model at the end of epoch 26, iters 21996
(epoch: 27, iters: 324, time: 0.042 lr: 0.00000) G_GAN: 0.988 G_GAN_Feat: 6.239 G_VGG: 8.989 G_KL: 0.743 D_real: 0.398 D_fake: 0.298
End of epoch 27 / 200 	 Time Taken: 125 sec
saving the model at the end of epoch 27, iters 22842
(epoch: 28, iters: 378, time: 0.044 lr: 0.00000) G_GAN: 1.059 G_GAN_Feat: 5.425 G_VGG: 9.404 G_KL: 0.765 D_real: 0.462 D_fake: 0.270
End of epoch 28 / 200 	 Time Taken: 38 sec
saving the model at the end of epoch 28, iters 23688
(epoch: 29, iters: 432, time: 0.044 lr: 0.00000) G_GAN: 1.062 G_GAN_Feat: 6.354 G_VGG: 7.967 G_KL: 0.718 D_real: 0.385 D_fake: 0.251
End of epoch 29 / 200 	 Time Taken: 38 sec
saving the model at the end of epoch 29, iters 24534
(epoch: 30, iters: 486, time: 0.043 lr: 0.00000) G_GAN: 1.072 G_GAN_Feat: 5.673 G_VGG: 9.224 G_KL: 0.783 D_real: 0.421 D_fake: 0.260
End of epoch 30 / 200 	 Time Taken: 110 sec
saving the model at the end of epoch 30, iters 25380
(epoch: 31, iters: 540, time: 0.044 lr: 0.00000) G_GAN: 0.985 G_GAN_Feat: 5.677 G_VGG: 10.715 G_KL: 0.770 D_real: 0.370 D_fake: 0.289
End of epoch 31 / 200 	 Time Taken: 55 sec
saving the model at the end of epoch 31, iters 26226
(epoch: 32, iters: 594, time: 0.042 lr: 0.00000) G_GAN: 1.082 G_GAN_Feat: 5.883 G_VGG: 8.674 G_KL: 0.692 D_real: 0.445 D_fake: 0.239
End of epoch 32 / 200 	 Time Taken: 513 sec
saving the model at the end of epoch 32, iters 27072
(epoch: 33, iters: 648, time: 0.041 lr: 0.00000) G_GAN: 1.000 G_GAN_Feat: 6.859 G_VGG: 9.097 G_KL: 0.740 D_real: 0.316 D_fake: 0.284
End of epoch 33 / 200 	 Time Taken: 109 sec
saving the model at the end of epoch 33, iters 27918
(epoch: 34, iters: 702, time: 0.042 lr: 0.00000) G_GAN: 1.107 G_GAN_Feat: 5.451 G_VGG: 8.401 G_KL: 0.710 D_real: 0.353 D_fake: 0.220
End of epoch 34 / 200 	 Time Taken: 130 sec
saving the model at the end of epoch 34, iters 28764
(epoch: 35, iters: 756, time: 0.042 lr: 0.00000) G_GAN: 1.054 G_GAN_Feat: 5.067 G_VGG: 8.589 G_KL: 0.727 D_real: 0.385 D_fake: 0.251
End of epoch 35 / 200 	 Time Taken: 525 sec
saving the model at the end of epoch 35, iters 29610
(epoch: 36, iters: 810, time: 0.041 lr: 0.00000) G_GAN: 1.036 G_GAN_Feat: 5.755 G_VGG: 9.931 G_KL: 0.792 D_real: 0.312 D_fake: 0.262
End of epoch 36 / 200 	 Time Taken: 70 sec
saving the model at the end of epoch 36, iters 30456
End of epoch 37 / 200 	 Time Taken: 35 sec
saving the model at the end of epoch 37, iters 31302
(epoch: 38, iters: 18, time: 0.020 lr: 0.00000) G_GAN: 1.023 G_GAN_Feat: 5.900 G_VGG: 8.975 G_KL: 0.721 D_real: 0.384 D_fake: 0.256
End of epoch 38 / 200 	 Time Taken: 591 sec
saving the model at the end of epoch 38, iters 32148
(epoch: 39, iters: 72, time: 0.043 lr: 0.00000) G_GAN: 0.886 G_GAN_Feat: 6.209 G_VGG: 10.360 G_KL: 0.828 D_real: 0.289 D_fake: 0.350
End of epoch 39 / 200 	 Time Taken: 36 sec
saving the model at the end of epoch 39, iters 32994
(epoch: 40, iters: 126, time: 0.042 lr: 0.00000) G_GAN: 0.975 G_GAN_Feat: 5.555 G_VGG: 8.256 G_KL: 0.719 D_real: 0.286 D_fake: 0.277
End of epoch 40 / 200 	 Time Taken: 47 sec
saving the model at the end of epoch 40, iters 33840
(epoch: 41, iters: 180, time: 0.043 lr: 0.00000) G_GAN: 1.349 G_GAN_Feat: 5.140 G_VGG: 8.754 G_KL: 0.698 D_real: 0.536 D_fake: 0.150
End of epoch 41 / 200 	 Time Taken: 262 sec
saving the model at the end of epoch 41, iters 34686
(epoch: 42, iters: 234, time: 12.241 lr: 0.00000) G_GAN: 1.161 G_GAN_Feat: 4.774 G_VGG: 8.717 G_KL: 0.699 D_real: 0.481 D_fake: 0.204
End of epoch 42 / 200 	 Time Taken: 523 sec
saving the model at the end of epoch 42, iters 35532
(epoch: 43, iters: 288, time: 0.061 lr: 0.00000) G_GAN: 1.224 G_GAN_Feat: 5.093 G_VGG: 7.652 G_KL: 0.680 D_real: 0.443 D_fake: 0.174
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f352a04a430>
Traceback (most recent call last):
  File "/home/quan/miniconda3/envs/photo/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1478, in __del__
    def __del__(self):
  File "/home/quan/miniconda3/envs/photo/lib/python3.8/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 228133) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.
Traceback (most recent call last):
  File "train_domain_B.py", line 99, in <module>
    losses, generated = model(Variable(data['label']), Variable(data['inst']),
  File "/home/quan/miniconda3/envs/photo/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/quan/miniconda3/envs/photo/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/quan/workspace/image-restoration/Global/models/pix2pixHD_model.py", line 167, in forward
    hiddens = self.netG.forward(input_concat, 'enc')
  File "/home/quan/workspace/image-restoration/Global/models/networks.py", line 285, in forward
    return self.encoder(input)
  File "/home/quan/miniconda3/envs/photo/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/quan/miniconda3/envs/photo/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/quan/miniconda3/envs/photo/lib/python3.8/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/quan/miniconda3/envs/photo/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/quan/miniconda3/envs/photo/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/quan/miniconda3/envs/photo/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 460, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/quan/miniconda3/envs/photo/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 456, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
KeyboardInterrupt